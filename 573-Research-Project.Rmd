---
title: "ECON573 Final Project"
author: 'Nicholas Wong'
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  pdf_document: default
---

R set-up 

```{r message = F}
library(tidyverse)
library(ISLR)
library(leaps)
library(glmnet)
library(pls)
library(MASS)
library(caret)
library(corrplot)
library(ggplot2)
library(sf)
library(RColorBrewer)
library(gridExtra)
library(modelr)
library(knitr)

airbnb <- read_csv("airbnb.csv",
                  col_select = -c("id", "amenities", "description", "name", "thumbnail_url", "neighbourhood", "zipcode"))
```

**Data cleaning/pre-processing** 
```{r}
set.seed(123)

# Mutate original price variable 
airbnb <- airbnb |> 
  mutate(price = exp(log_price)) 

# Drop NAs
airbnb <- na.omit(airbnb) 

# host_response_rate to numeric for easier interpretation 
airbnb <- airbnb |> 
  mutate(host_response_rate = str_replace_all(host_response_rate, pattern = "%", replacement = "")) |> 
  mutate_at(13, as.numeric) 

# 80/20 train/test split 
training_indices <- sample(1:nrow(airbnb), .8*nrow(airbnb))

# Split data into train and test sets 
train <- airbnb[training_indices, ]
test <- airbnb[-training_indices, ] # true unseen data for model testing

totalData <- rbind(train, test)
for (f in 1:length(names(totalData))) {
  levels(train[, f]) <- levels(totalData[, f])
  levels(test[,f]) <- levels(totalData[, f])
}
```

# Method 1 - Forward Selection # 

Here, we use a validation set approach due to the heavy computational expense of using stepwise methods with K-fold CV. 

_Fitting forward selection on training set_
```{r}
full = lm(price ~., data=train)
none = lm(price ~., data = train)
MSE = (summary(full)$sigma)^2
forward_selection_mod <- step(none, scope = list(upper = full), scale = MSE, direction = 'forward', trace=T)

summary(forward_selection_mod)
plot(forward_selection_mod)
```

Get predictions and residuals for forward selection, compute MSE 
```{r}
test_forwardselection <- test |> add_predictions(forward_selection_mod, var = "forward_pred")
test_forwardselection <- test_forwardselection |> add_residuals(forward_selection_mod, var = "forward_resid")

# Args: vector of residuals
# Return: MSE 
MSE_func <- function(resid){
  return(mean(resid^2))
}

MSE_func(test_forwardselection$forward_resid)
```

MSE for forward selection: 4395.526 

# Method 2 - Lasso # 

```{r}

```


# Cluster Analysis # 

Top 3 priced listings
```{r}
head(airbnb |> arrange(desc(log_price)) |>  dplyr::select(log_price, city), 3) |> kable()
```
2 out of 3 top listings are from NYC. Perform cluster analysis in NYC 

_Beginning NYC cluster analysis_ 

This section requires the accompanying files nyc_boundaries.shp and nyc_boundaries.shx to run (to aid with the geographic map overlay).
```{r, eval = T}
airbnb <- read_csv("airbnb.csv",
                  col_select = -c("id", "amenities", "description", "name", "thumbnail_url"))

airbnb_NYC <- airbnb |> 
  filter(city == 'NYC') |> 
  filter(!is.na(neighbourhood)) |> 
  filter(log_price >= 0.01)
```

Here, we create a best_value variable for NYC neighbourhoods, and pick the top 500 to work with.
```{r, eval = T}
airbnb_NYC |> 
  group_by(neighbourhood) |> 
  filter(!is.na(neighbourhood)) |> 
  mutate(best_value = review_scores_rating/log_price) |> 
  arrange(desc(best_value))

top500_NYC <- head(airbnb_NYC, 500)
```

```{r, eval = T}
num_listings = table(airbnb_NYC$neighbourhood)

top500_NYC_nbr <- top500_NYC |> 
  group_by(neighbourhood) |> 
  filter(num_listings[as.character(neighbourhood)] > 50) |> 
  summarize(count = n()) |> 
  mutate(standardized_value = (round(100 * count/num_listings[as.character(neighbourhood)], digits = 4))) |>
  mutate(count_listings = num_listings[as.character(neighbourhood)]) |> 
  arrange(desc(standardized_value)) |> 
  ungroup()
```

```{r, eval = T}
top500_locations <- full_join(top500_NYC_nbr, top500_NYC, join_by(neighbourhood)) |> 
  dplyr::select(neighbourhood, count, standardized_value, longitude, latitude)
  
top500 <- top500_locations |> 
  group_by(neighbourhood) |> 
  mutate(mean_long = mean(longitude),
         mean_lat = mean(latitude),
         standardized_value = as.numeric(standardized_value)) |> 
  arrange(desc(standardized_value)) |> 
  distinct(neighbourhood, standardized_value, count, mean_long, mean_lat)
  
top10_nbr <- head(top500, 10)
```

Here, we calculate density of best value listings based on standardized best value in neighborhoods within the top 500 Best Value AirBnb listings in NY. 
```{r, eval = T}
nyc <- sf::st_read(dsn = "nyc_boundaries.shp", quiet = TRUE)

  ggplot() +
  geom_sf(data = nyc, fill = "#d9f2f2") +
  ggtitle("Best Value AirBnbs in NYC Neighborhoods") +
  geom_point(data = top10_nbr, aes(x = mean_long, y = mean_lat, size = as.numeric(standardized_value), color = as.factor(neighbourhood))) +
    scale_size_continuous(range = c(1, 4)) +
  guides(size = guide_legend(title = "Density of Best Value Listings")) +
  guides(color = guide_legend(title = "Neighborhood")) + theme_minimal()
```