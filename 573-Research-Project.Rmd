---
title: "ECON573 Final Project"
author: 'Nicholas Wong'
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  pdf_document: default
---

```{r message = F, include = F}
library(tidyverse)
library(ISLR)
library(leaps)
library(glmnet)
library(pls)
library(MASS)
library(caret)
library(corrplot)
library(ggplot2)
library(sf)
library(RColorBrewer)
library(gridExtra)
library(modelr)
library(knitr)
library(gbm)
library(corrplot)

airbnb <- read_csv("airbnb.csv",
                  col_select = -c("id", "amenities", "description", "name", "thumbnail_url", "neighbourhood", "zipcode"))
```

**Data cleaning/pre-processing** 
```{r}
set.seed(123)

# Mutate original price variable 
airbnb <- airbnb |> 
  mutate(price = exp(log_price),
         log_price = NULL) 

# Drop NAs
airbnb <- na.omit(airbnb) 

# host_response_rate to numeric for easier interpretation 
airbnb <- airbnb |> 
  mutate(host_response_rate = str_replace_all(host_response_rate, pattern = "%", replacement = "")) |> 
  mutate_at(12, as.numeric) 

# typecast to factors for fitting boosting
airbnb <- airbnb |> 
  mutate(property_type = as.factor(property_type),
         room_type = as.factor(room_type),
         bed_type = as.factor(bed_type),
         cancellation_policy = as.factor(cancellation_policy),
         cleaning_fee = as.factor(cleaning_fee),
         city = as.factor(city),
         host_has_profile_pic = as.factor(host_has_profile_pic),
         host_identity_verified = as.factor(host_identity_verified),
         instant_bookable = as.factor(instant_bookable)) 


# 80/20 train/test split 
training_indices <- sample(1:nrow(airbnb), .8*nrow(airbnb))

# Split data into train and test sets 
train <- airbnb[training_indices, ]
test <- airbnb[-training_indices, ] 

# relevel factors for train/test CV
totalData <- rbind(train, test)
for (f in 1:length(names(totalData))) {
  levels(train[, f]) <- levels(totalData[, f])
  levels(test[,f]) <- levels(totalData[, f])
}
```

# Method 1 - Forward Selection # 

Here, we use a validation set approach due to the heavy computational expense of using stepwise methods with K-fold CV. 

_Fitting forward selection on training set_
```{r}
full = lm(price ~., data=train)
none = lm(price ~1, data = train)
MSE = (summary(full)$sigma)^2
forward_selection_mod <- step(none, scope = list(upper = full), scale = MSE, direction = 'forward', trace=T)

summary(forward_selection_mod)
plot(forward_selection_mod, 1)
```

Get predictions and residuals for forward selection, compute MSE 
```{r}
test_forwardselection <- test |> add_predictions(forward_selection_mod, var = "forward_pred")
test_forwardselection <- test_forwardselection |> add_residuals(forward_selection_mod, var = "forward_resid")

# Args: vector of residuals
# Return: RMSE 
RMSE_func <- function(resid){
  return(sqrt(mean(resid^2)))
}

(forward_selection_RMSE <- RMSE_func(test_forwardselection$forward_resid))
```

# Method 2 - LASSO # 

Here, we select shrinkage parameter $\lambda$ for LASSO through repeated 5-fold CV. 
We test a range of 16 different $\lambda$ values in (0, 0.3), in equally spaced increments of 0.02.
```{r warning = F}
ctrl <- trainControl(method = "repeatedcv", number = 5, repeats = 10, verboseIter = F)

set.seed(1)

model_lasso <- train(price ~ ., 
                   data = train, 
                   method = "glmnet", 
                   preProcess = c("center", "scale"), 
                     metric = "RMSE",
                     maximize = F,
                     trControl = ctrl, 
                     tuneGrid = expand.grid(alpha = 1, # lasso specification
                                            lambda = seq(0, 0.3, 0.02)))

model_lasso$results |> 
  rename(CV_RMSE = RMSE) |> 
  mutate(min_CV_RMSE = as.numeric(lambda == model_lasso$bestTune$lambda)) |> 
  ggplot(aes(x = lambda, y = CV_RMSE)) + 
  geom_line(col = "grey55") + 
  geom_point(size = 2, aes(col = factor(min_CV_RMSE))) + 
  scale_color_manual(values = c("deepskyblue3", "green")) + 
  theme(legend.position = "none") + 
  labs(title = "AirBnB - Lasso Regression", 
       subtitle = "Hyperparameter Tuning - Selecting shrinkage parameter with cross-validation",
       y = "CV RMSE")
```


Optimal shrinkage ($\lambda$): 
```{r}
model_lasso$bestTune$lambda 
```

CV RMSE:
```{r }
(lasso_cv <- min(model_lasso$results$RMSE) |>  round(4))
```

Test RMSE: 
```{r }
(lasso_test_RMSE <- sqrt(mean((predict(model_lasso, test) - test$price)^2)) |>  round(4))
```

Predictors in final fitted LASSO model: 
```{r}
tibble(names = model_lasso$coefnames) |> kable()
```

# Method 3 - Boosting # 

```{r warning = F}
lambda_seq <- 10^seq(-6, 0, 0.1)

set.seed(123)

train_MSE <- c()
test_MSE <- c()


for (i in 1:length(lambda_seq)) {
  boost_TEMP <- gbm(price ~ . -first_review -host_since -last_review, 
                    data = train, 
                    distribution = "gaussian", 
                    n.trees = 1000, 
                    interaction.depth = 2, 
                    shrinkage = lambda_seq[i])
  
  train_MSE[i] <- mean((predict(boost_TEMP, train, n.trees = 1000) - train$price)^2)
  
  test_MSE[i] <- mean((predict(boost_TEMP, test, n.trees = 1000) - test$price)^2)
}

df <- data.frame(lambda = lambda_seq, test_MSE) |> 
  mutate(min_MSE = as.numeric(test_MSE == min(test_MSE))) 

df |> 
  ggplot(aes(x = lambda, y = test_MSE)) + 
  geom_point(size = 2, aes(col = factor(min_MSE))) + 
  geom_line(col = "grey55") + 
  scale_color_manual(values = c("deepskyblue", "green")) +
  theme(legend.position = "none") + 
  scale_x_continuous(trans = 'log10', breaks = 10^seq(-6, 0), labels = 10^seq(-6, 0), minor_breaks = NULL) + 
  labs(x = "Lambda (Shrinkage)", 
       y = "Test MSE") +
  labs(title = "AirBnB - Boosting Hyperparameter Tuning", 
       subtitle = "Selecting shrinkage parameter for boosting with cross-validation",
       y = "Test Set RMSE")

(boosting_RMSE <- sqrt(df$test_MSE[which(df$min_MSE == 1)]))
(boosting_lambda <- df$lambda[which(df$min_MSE == 1)])
```
```{r}

```


# Method 4 - Polynomial #

First, we perform an exploratory data analysis (EDA) to find the variable for polynomial fit
```{r}
airbnb_numeric <- airbnb[, sapply(airbnb, is.numeric)]
corrplot::corrplot(cor(airbnb_numeric))
```

Highest correlation with "accommodates". Use accommodates for polynomial fit.

Here, we opt for K-fold CV to choose the optimal degree for the polynomial. 
We perform 10-fold CV with 5 repeats.

```{r eval = F}
ctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 5)

CV_RMSE <- c()

set.seed(159)

for (i in 1:10) {
  model_temp <- train(y = train$price,
                      x = poly(train$accommodates, i, raw = T, simple = T),
                      method = "lm",
                      metric = "RMSE",
                      trControl = ctrl)
  CV_RMSE[i] <- model_temp$results$RMSE
}

data.frame(degree = 1:10, CV_RMSE = CV_RMSE) |> 
  mutate(min_CV_RMSE = as.numeric(min(CV_RMSE) == CV_RMSE)) |> 
  ggplot(aes(x = degree, y = CV_RMSE)) +
  geom_line(col = "grey55") +
  geom_point(size = 2, aes(col = factor(min_CV_RMSE))) +
  scale_x_continuous(breaks = seq(1, 10), minor_breaks = NULL) +
  scale_y_continuous(breaks = seq(0, 0.03, 0.002)) +
  scale_color_manual(values = c("deepskyblue3", "green")) +
  theme(legend.position = "none") +
  labs(title = "AirBnB Dataset - Polynomial Regression Hyperparameter Tuning",
       subtitle = "Selecting the 'accommodates' polynomial degree with cross-validation RMSE",
       x = "Degree",
       y = "Cross-Validation RMSE")
```
We find that polynomial degree 6 minimizes RMSE

```{r eval = F}
# store minimum polynomial RMSE for reference
(min_poly_RMSE_raw <- min(CV_RMSE))
```
Now, we use a validation set approach to test on unseen test data
```{r}
polymod <- lm(price ~ poly(accommodates, 6, raw = T), data = train)

test_poly <- test |> add_predictions(polymod, var = "poly_pred")
test_poly <- test_poly |> add_residuals(polymod, var = "poly_resid")

(poly_RMSE <- RMSE_func(test_poly$poly_resid))
```

```{r}
#summary(polymod)
tidy(polymod)
```

# Summary of test error for methods 

```{r}
(RMSE_summary <- tibble(Method = c("Forward Selection", "LASSO", "Polynomial Regression", "Boosting"), RMSE = c(forward_selection_RMSE, lasso_test_RMSE, poly_RMSE, boosting_RMSE)))

RMSE_summary |> 
  mutate(min_RMSE = as.numeric(min(RMSE) == RMSE)) |> 
  ggplot(aes(x = Method, y = RMSE)) + 
  geom_col(aes(fill = factor(min_RMSE), color = factor(min_RMSE))) +
  scale_fill_manual(values = c("deepskyblue", "green")) + 
  scale_color_manual(values = c("black", "red")) +
  theme(legend.position = "none") +
  labs(title = "AirBnB Dataset - Test RMSE summary",
       subtitle = "Predictive performance of various models on 20% unseen held-out data",
       x = "Method",
       y = "Validation Set RMSE")
```



######################################################REF############################################################

```{r}
summary(model_gbm$finalModel)

# ggplot version:
summary(model_gbm$finalModel, plotit = F) %>%
  rename("Importance" = "rel.inf") %>%
  ggplot(aes(x = reorder(var, Importance), y = Importance, fill = Importance)) + 
  geom_bar(stat = "identity") + 
  geom_text(aes(label = round(Importance, 2), col = Importance), hjust = -0.2) + 
  scale_y_continuous(limits = c(0, 31.5)) +
  scale_fill_gradient(low = "grey40", high = "#28B463") + 
  scale_color_gradient(low = "grey40", high = "#28B463") +
  coord_flip() + 
  theme(legend.position = "none") + 
  labs(title = "Hitters Dataset - Boosting - Variable Importance", 
       x = "Varname")
```


#########################################################################################################################

# Cluster Analysis for NYC # 

Top 3 priced listings
```{r eval = F}
head(airbnb |> arrange(desc(log_price)) |>  dplyr::select(log_price, city), 3) |> kable()
```
2 out of 3 top listings are from NYC. Perform cluster analysis in NYC 

_Beginning NYC cluster analysis_ 

This section requires the accompanying files nyc_boundaries.shp and nyc_boundaries.shx to run (to aid with the geographic map overlay).
```{r, eval = F}
airbnb <- read_csv("airbnb.csv",
                  col_select = -c("id", "amenities", "description", "name", "thumbnail_url"))

airbnb_NYC <- airbnb |> 
  filter(city == 'NYC') |> 
  filter(!is.na(neighbourhood)) |> 
  filter(log_price >= 0.01)
```

Here, we create a best_value variable for NYC neighbourhoods, and pick the top 500 to work with.
```{r, eval = F}
airbnb_NYC |> 
  group_by(neighbourhood) |> 
  filter(!is.na(neighbourhood)) |> 
  mutate(best_value = review_scores_rating/log_price) |> 
  arrange(desc(best_value))

top500_NYC <- head(airbnb_NYC, 500)
```

```{r, eval = F}
num_listings = table(airbnb_NYC$neighbourhood)

top500_NYC_nbr <- top500_NYC |> 
  group_by(neighbourhood) |> 
  filter(num_listings[as.character(neighbourhood)] > 50) |> 
  summarize(count = n()) |> 
  mutate(standardized_value = (round(100 * count/num_listings[as.character(neighbourhood)], digits = 4))) |>
  mutate(count_listings = num_listings[as.character(neighbourhood)]) |> 
  arrange(desc(standardized_value)) |> 
  ungroup()
```

```{r, eval = F}
top500_locations <- full_join(top500_NYC_nbr, top500_NYC, join_by(neighbourhood)) |> 
  dplyr::select(neighbourhood, count, standardized_value, longitude, latitude)
  
top500 <- top500_locations |> 
  group_by(neighbourhood) |> 
  mutate(mean_long = mean(longitude),
         mean_lat = mean(latitude),
         standardized_value = as.numeric(standardized_value)) |> 
  arrange(desc(standardized_value)) |> 
  distinct(neighbourhood, standardized_value, count, mean_long, mean_lat)
  
top10_nbr <- head(top500, 10)
```

Here, we calculate density of best value listings based on standardized best value in neighborhoods within the top 500 Best Value AirBnb listings in NY. 
```{r, eval = F}
nyc <- sf::st_read(dsn = "nyc_boundaries.shp", quiet = TRUE)

  ggplot() +
  geom_sf(data = nyc, fill = "#d9f2f2") +
  ggtitle("Best Value AirBnbs in NYC Neighborhoods") +
  geom_point(data = top10_nbr, aes(x = mean_long, y = mean_lat, size = as.numeric(standardized_value), color = as.factor(neighbourhood))) +
    scale_size_continuous(range = c(1, 4)) +
  guides(size = guide_legend(title = "Density of Best Value Listings")) +
  guides(color = guide_legend(title = "Neighborhood")) + theme_minimal()
```